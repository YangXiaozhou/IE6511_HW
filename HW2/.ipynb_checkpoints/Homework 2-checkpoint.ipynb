{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IE6511 Homework 1 \n",
    "Done by: Aloisius Stephen and Yang Xiaozhou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "font = {'family' : 'sans-serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 12}\n",
    "\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. Homework on Genetic Algorithm\n",
    "\n",
    "1. A binary string of length 4 <br> <br>\n",
    "\n",
    "2.  Parent one before crossover: 0010, after crossover: 0010<br>\n",
    "    Parent two before crossover: 0011, after crossover: 0011<br> <br>\n",
    "    Parent three before crossover: 0011, after crossover: 1011<br>\n",
    "    Parent four  before crossover: 1010, after crossover: 0010 <br><br>\n",
    "\n",
    "3. Pair one children: 0010 and 0011 <br>\n",
    "   Pair two children: 1011 and 0010 <br> <br>\n",
    "\n",
    "4. After mutation, <br>\n",
    "   Pair one children: 0000 and 0001 <br>\n",
    "   Pair two children: 1001 and 0000 <br> <br>\n",
    "\n",
    "5. x and f(x) values of children: <br>\n",
    "    children one, x = 0, f(x) = 0 <br>\n",
    "    children two, x = 1, f(x) = 1 <br>\n",
    "    children three, x = 9, f(x) = 6561 <br>\n",
    "    children four, x = 0, f(x) = 0 <br>\n",
    "\n",
    "    Total f(x) = 6561+ 1 = 6562\n",
    "\n",
    "    Probability of being selected: <br>\n",
    "    children one, p = 0 <br>\n",
    "    children two, p = 1/6562 <br>\n",
    "    children three, p = 6561/6562 <br>\n",
    "    children four, p = 0 <br> <br>\n",
    "\n",
    "6. Binary strings of parents: <br>\n",
    "    Parent one: 0110 0010 1001 <br>\n",
    "    Parent two: 0001 0010 0011 <br>\n",
    "    \n",
    "    Children binary strings, x value (Crossover point 3): <br>\n",
    "    Children one: 0111 0010 0011, x = (7,2,3) <br>\n",
    "    Children two: 0000 0010 1001, x = (0,2,9) <br>\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated Annealing\n",
    "\n",
    "### 2. SA Parameter Selection when cost function range = (MaxCost and MinCost) are known\n",
    "<no code>\n",
    "\n",
    "a) \n",
    "\n",
    "b)\n",
    "\n",
    "c)\n",
    "\n",
    "d)\n",
    "\n",
    "e)\n",
    "\n",
    "### 3. SA Parameter Selection when you have computed AP cost values (no coding necessary)  \n",
    "<no code>\n",
    "\n",
    "### 4. SA Implementation (requires writing a Simulated Annealing code, preferably in python, matlab or  C)  Instructions below are for Matlab.\n",
    "<coding>\n",
    "\n",
    "Write a Matlab function called cost.m that returns the value of the above function.  The input argument should be S (a vector).\n",
    "  \n",
    "Define the neighborhood function using a function called neighbor.m.  The neighborhood should be randomly perturb one of the two decision variables current value between max(s-25,0) and min(s+25, 127). Note that the neighborhood function should not select s as a neighbor of itself, i.e. neighbor(s) ≠ s. If you wish, it may be easier to code this if you select the decision variable to be perturbed within the SA code and then call neighbor.m to make the one-dimensional perturbation.  Note that in general, as problems increase in dimension, the definition of the neighborhood can become more complex.\n",
    "\n",
    "Submit a printout of the code for SA.m, cost.m and neighbor.m.  Debug thoroughly as you will reuse the SA code in future homeworks!  If you care to return other output variables from SA.m, such as scurrent (perhaps for debugging/interest), please output them to additional output variables (not solution or BestS) that you define in your SA code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Running SA: \n",
    "\n",
    "a) Let beta = 1, M = 1, Maxtime = 1100, P1 of accepting an uphill move is to be 0.9, and the probability of accepting an uphill move after the 1000th iteration (P2) is to be .05. What should To, T2, and alpha be?  (T2 is the temperature after 1000 iterations.) Write a script that calculates an estimate of averageCost for an uphill move by Method 2 with AP=20. Call this script SAparameter.m\n",
    "\n",
    "b) Use the values of To and α from 4a) above.   Generate 30 sets of random integer numbers sinitial (where 0≤ s1,s2 ≤ 127) and call this set Z. Now run 30 trials of SA algorithm each with starting value So = sinitiali, for i=1…,30 and sinitiali in Z. (Let Sinitial be the initial value of S at iteration 0, then start counting iterations for each trial  after the SA algorithm is called) You should NOT recalculate the SA parameters for each trial. \n",
    "Submit a plot of the average of BestCost & CurCost (averaged over all 30 runs) vs. iterations for the SA algorithm, evaluated at G=1000. Compute and report the average and standard deviation (use the MATLAB command ‘std’) of BestCost over all 30 runs after 1000 iterations.   Also report the average CPU time it takes to do one SA run (use the MATLAB command “cputime”  or “tic; toc”). \n",
    "\n",
    "c) Now repeat steps 4a, 4b, with P1=0.7, while keeping P2= 0.05, beta = 1, M = 1, G=1000 ,Maxtime = 1100.  For the new value  of P1 you will have to compute a new corresponding To and alpha based on your sampled average DCost from part a).   (You can use the same AP points computed in part 4a).\n",
    "Run the SA 30 times for P1=0.7 and compare the average of BestCost after 1100 iterations for each value of P1.  Which value of P1 works best? (you should run SA 30 times using the same initial points from set Z of part 4b above).\n",
    "\n",
    "d) The simulated annealing runs after 1000 iterations have a probability 0.05 of accepting an uphill move, so iterations between 1000 and 1100 are mostly greedy search. Do you see much improvement during these last 100 iterations? (Compare values at G=1000 and Maxtime=1100). When you implement SA, let P continue decreasing from 0.05 after the G=1000th iteration , but calculate the parameters for the SA algorithm P2  at G=1000th iteration to be 0.05.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
